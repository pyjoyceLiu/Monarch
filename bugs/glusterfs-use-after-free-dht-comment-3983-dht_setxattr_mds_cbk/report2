#0 [34078ms] <- syz_failure_recv=0x0 errno=14  /root
execute_call 0, 1, 0, 0
execute_one loop: 0, 0, 1
#0 [34078ms] -> syz_failure_net_up() 3786 /root
=================================================================
==415==ERROR: AddressSanitizer: heap-use-after-free on address 0x621000161034 at pc 0x7fffeeff13c6 bp 0x7ffff027e620 sp 0x7ffff027e610
READ of size 4 at 0x621000161034 thread T6
    #0 0x7fffeeff13c5 in dht_setxattr_mds_cbk /root/glusterfs/xlators/cluster/dht/src/dht-common.c:3983
    #1 0x7fffef1e96b1 in client4_0_setxattr_cbk /root/glusterfs/xlators/protocol/client/src/client-rpc-fops_v2.c:865
    #2 0x7ffff721ffca in rpc_clnt_handle_reply /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:723
    #3 0x7ffff721ffca in rpc_clnt_notify /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:890
    #4 0x7ffff7219983 in rpc_transport_notify /root/glusterfs/rpc/rpc-lib/src/rpc-transport.c:521
    #5 0x7ffff03405a6 in socket_event_poll_in_async /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2358
    #6 0x7ffff0350b39 in gf_async ../../../../libglusterfs/src/glusterfs/async.h:187
    #7 0x7ffff0350b39 in socket_event_poll_in /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2399
    #8 0x7ffff0350b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2790
    #9 0x7ffff0350b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2710
    #10 0x7ffff73fa6c0 in event_dispatch_epoll_handler /root/glusterfs/libglusterfs/src/event-epoll.c:631
    #11 0x7ffff73fa6c0 in event_dispatch_epoll_worker /root/glusterfs/libglusterfs/src/event-epoll.c:742
    #12 0x7ffff71bf608 in start_thread /build/glibc-YYA7BZ/glibc-2.31/nptl/pthread_create.c:477
    #13 0x7ffff70e4102 in __clone (/lib/x86_64-linux-gnu/libc.so.6+0x122102)

0x621000161034 is located 1844 bytes inside of 4164-byte region [0x621000160900,0x621000161944)
freed by thread T6 here:
    #0 0x7ffff769a7cf in __interceptor_free (/lib/x86_64-linux-gnu/libasan.so.5+0x10d7cf)
    #1 0x7ffff7355e19 in __gf_free /root/glusterfs/libglusterfs/src/mem-pool.c:383
    #2 0x7fffeef71acd in dht_local_wipe /root/glusterfs/xlators/cluster/dht/src/dht-helper.c:805
    #3 0x7fffeef71acd in dht_local_wipe /root/glusterfs/xlators/cluster/dht/src/dht-helper.c:713
    #4 0x7fffef05d734 in dht_setxattr_non_mds_cbk /root/glusterfs/xlators/cluster/dht/src/dht-common.c:3886
    #5 0x7fffef1e96b1 in client4_0_setxattr_cbk /root/glusterfs/xlators/protocol/client/src/client-rpc-fops_v2.c:865
    #6 0x7fffef1995ac in client_submit_request /root/glusterfs/xlators/protocol/client/src/client.c:288
    #7 0x7fffef1cd175 in client4_0_setxattr /root/glusterfs/xlators/protocol/client/src/client-rpc-fops_v2.c:4171
    #8 0x7fffef19757f in client_setxattr /root/glusterfs/xlators/protocol/client/src/client.c:1259
    #9 0x7fffeefed8cb in dht_setxattr_mds_cbk /root/glusterfs/xlators/cluster/dht/src/dht-common.c:3965
    #10 0x7fffef1e96b1 in client4_0_setxattr_cbk /root/glusterfs/xlators/protocol/client/src/client-rpc-fops_v2.c:865
    #11 0x7ffff721ffca in rpc_clnt_handle_reply /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:723
    #12 0x7ffff721ffca in rpc_clnt_notify /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:890
    #13 0x7ffff7219983 in rpc_transport_notify /root/glusterfs/rpc/rpc-lib/src/rpc-transport.c:521
    #14 0x7ffff03405a6 in socket_event_poll_in_async /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2358
    #15 0x7ffff0350b39 in gf_async ../../../../libglusterfs/src/glusterfs/async.h:187
    #16 0x7ffff0350b39 in socket_event_poll_in /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2399
    #17 0x7ffff0350b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2790
    #18 0x7ffff0350b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2710
    #19 0x7ffff73fa6c0 in event_dispatch_epoll_handler /root/glusterfs/libglusterfs/src/event-epoll.c:631
    #20 0x7ffff73fa6c0 in event_dispatch_epoll_worker /root/glusterfs/libglusterfs/src/event-epoll.c:742
    #21 0x7ffff71bf608 in start_thread /build/glibc-YYA7BZ/glibc-2.31/nptl/pthread_create.c:477

previously allocated by thread T8 here:
    #0 0x7ffff769adc6 in calloc (/lib/x86_64-linux-gnu/libasan.so.5+0x10ddc6)
    #1 0x7ffff7355226 in __gf_calloc /root/glusterfs/libglusterfs/src/mem-pool.c:177
    #2 0x7fffeef7db19 in dht_local_init /root/glusterfs/xlators/cluster/dht/src/dht-helper.c:815
    #3 0x7fffef06cc91 in dht_setxattr /root/glusterfs/xlators/cluster/dht/src/dht-common.c:5796
    #4 0x7ffff747be59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #5 0x7ffff747be59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #6 0x7ffff747be59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #7 0x7fffeeeb4f21 in ob_setxattr /root/glusterfs/xlators/performance/open-behind/src/open-behind.c:777
    #8 0x7fffeeeb4f21 in ob_setxattr /root/glusterfs/xlators/performance/open-behind/src/open-behind.c:768
    #9 0x7ffff747be59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #10 0x7fffeee41023 in mdc_setxattr /root/glusterfs/xlators/performance/md-cache/src/md-cache.c:2403
    #11 0x7ffff74d1bf0 in default_setxattr_resume /root/glusterfs/libglusterfs/src/defaults.c:1745
    #12 0x7ffff731dfb6 in call_resume_wind /root/glusterfs/libglusterfs/src/call-stub.c:2073
    #13 0x7ffff734d8f4 in call_resume /root/glusterfs/libglusterfs/src/call-stub.c:2390
    #14 0x7fffeee168bc in iot_worker /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:227
    #15 0x7ffff71bf608 in start_thread /build/glibc-YYA7BZ/glibc-2.31/nptl/pthread_create.c:477

Thread T6 created by T0 here:
    #0 0x7ffff75c7805 in pthread_create (/lib/x86_64-linux-gnu/libasan.so.5+0x3a805)
    #1 0x7ffff72f8b97 in gf_thread_vcreate /root/glusterfs/libglusterfs/src/common-utils.c:3261
    #2 0x7ffff730a28d in gf_thread_create /root/glusterfs/libglusterfs/src/common-utils.c:3284
    #3 0x7ffff73f8af2 in event_dispatch_epoll /root/glusterfs/libglusterfs/src/event-epoll.c:797
    #4 0x7ffff7353f89 in gf_event_dispatch /root/glusterfs/libglusterfs/src/event.c:115
    #5 0x7ffff7461b7f in gf_io_main /root/glusterfs/libglusterfs/src/gf-io.c:431
    #6 0x7ffff7461b7f in gf_io_run /root/glusterfs/libglusterfs/src/gf-io.c:516
    #7 0x55555556c37a in main /root/glusterfs/glusterfsd/src/glusterfsd.c:2774
    #8 0x7ffff6fe90b2 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x270b2)

Thread T8 created by T7 here:
    #0 0x7ffff75c7805 in pthread_create (/lib/x86_64-linux-gnu/libasan.so.5+0x3a805)
    #1 0x7ffff72f8b97 in gf_thread_vcreate /root/glusterfs/libglusterfs/src/common-utils.c:3261
    #2 0x7ffff730a28d in gf_thread_create /root/glusterfs/libglusterfs/src/common-utils.c:3284
    #3 0x7fffeee15ace in __iot_workers_scale /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:830
    #4 0x7fffeee1dd62 in iot_workers_scale /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:853
    #5 0x7fffeee1dd62 in init /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:1251
    #6 0x7ffff72e5208 in __xlator_init /root/glusterfs/libglusterfs/src/xlator.c:610
    #7 0x7ffff72e5208 in xlator_init /root/glusterfs/libglusterfs/src/xlator.c:635
    #8 0x7ffff7378672 in glusterfs_graph_init /root/glusterfs/libglusterfs/src/graph.c:474
    #9 0x7ffff737971b in glusterfs_graph_activate /root/glusterfs/libglusterfs/src/graph.c:823
    #10 0x555555573a4e in glusterfs_process_volfp /root/glusterfs/glusterfsd/src/glusterfsd.c:2493
    #11 0x555555584675 in mgmt_getspec_cbk /root/glusterfs/glusterfsd/src/glusterfsd-mgmt.c:2444
    #12 0x7ffff721ffca in rpc_clnt_handle_reply /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:723
    #13 0x7ffff721ffca in rpc_clnt_notify /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:890
    #14 0x7ffff7219983 in rpc_transport_notify /root/glusterfs/rpc/rpc-lib/src/rpc-transport.c:521
    #15 0x7ffff03405a6 in socket_event_poll_in_async /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2358
    #16 0x7ffff0350b39 in gf_async ../../../../libglusterfs/src/glusterfs/async.h:187
    #17 0x7ffff0350b39 in socket_event_poll_in /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2399
    #18 0x7ffff0350b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2790
    #19 0x7ffff0350b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2710
    #20 0x7ffff73fa6c0 in event_dispatch_epoll_handler /root/glusterfs/libglusterfs/src/event-epoll.c:631
    #21 0x7ffff73fa6c0 in event_dispatch_epoll_worker /root/glusterfs/libglusterfs/src/event-epoll.c:742
    #22 0x7ffff71bf608 in start_thread /build/glibc-YYA7BZ/glibc-2.31/nptl/pthread_create.c:477

Thread T7 created by T0 here:
    #0 0x7ffff75c7805 in pthread_create (/lib/x86_64-linux-gnu/libasan.so.5+0x3a805)
    #1 0x7ffff72f8b97 in gf_thread_vcreate /root/glusterfs/libglusterfs/src/common-utils.c:3261
    #2 0x7ffff730a28d in gf_thread_create /root/glusterfs/libglusterfs/src/common-utils.c:3284
    #3 0x7ffff73f8af2 in event_dispatch_epoll /root/glusterfs/libglusterfs/src/event-epoll.c:797
    #4 0x7ffff7353f89 in gf_event_dispatch /root/glusterfs/libglusterfs/src/event.c:115
    #5 0x7ffff7461b7f in gf_io_main /root/glusterfs/libglusterfs/src/gf-io.c:431
    #6 0x7ffff7461b7f in gf_io_run /root/glusterfs/libglusterfs/src/gf-io.c:516
    #7 0x55555556c37a in main /root/glusterfs/glusterfsd/src/glusterfsd.c:2774
    #8 0x7ffff6fe90b2 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x270b2)

SUMMARY: AddressSanitizer: heap-use-after-free /root/glusterfs/xlators/cluster/dht/src/dht-common.c:3983 in dht_setxattr_mds_cbk
Shadow bytes around the buggy address:
  0x0c42800241b0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c42800241c0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c42800241d0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c42800241e0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c42800241f0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
=>0x0c4280024200: fd fd fd fd fd fd[fd]fd fd fd fd fd fd fd fd fd
  0x0c4280024210: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c4280024220: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c4280024230: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c4280024240: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c4280024250: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07 
  Heap left redzone:       fa
  Freed heap region:       fd
  Stack left redzone:      f1
  Stack mid redzone:       f2
  Stack right redzone:     f3
  Stack after return:      f5
  Stack use after scope:   f8
  Global redzone:          f9
  Global init order:       f6
  Poisoned by user:        f7
  Container overflow:      fc
  Array cookie:            ac
  Intra object redzone:    bb
  ASan internal:           fe
  Left alloca redzone:     ca
  Right alloca redzone:    cb
  Shadow gap:              cc
==415==ABORTING
execute_one loop: 0, 0, 1001
#1 [35065ms] -> syz_failure_sync(#0 [35071ms] <- syz_failure_recv=0x0 errno=14 0x3, 0x3) 3789 /root/glusterfs-client/dfs-0-6
cover_reset in execute_call
 /root
execute_call 0, 1034, 0, 0
execute_one loop: 0, 0, 1034
#0 [35071ms] -> syz_failure_net_up() 3786 /root
2023/01/25 20:03:50 poll: candidates=0 inputs=0 signal=0
execute_one loop: 0, 0, 1001
#0 [36087ms] <- syz_failure_net_up=0x0 errno=14 #0 [36079ms] <- syz_failure_sync=0x0 errno=14 cover=0  /root/glusterfs-client/dfs-0-6
 /root
execute_call 0, 2015, 0, 0
execute_one loop: 0, 0, 2015
#0 [36094ms] -> syz_failure_send(0x1) 3788 /root
#0 [36094ms] <- syz_failure_send=0x0 errno=14  /root
execute_call 0, 0, 0, 0
execute_one loop: 0, 0, 0
execute_one inner time: 0, 2096, 0
execute_one time: 1, 2096
----- executor 3 write_call_output, size 0, pid 456, write pid:457
----- executor 3 executes write_coverage_signal cov->size 0, flag collect 1
----- executor 3 cover number : 0, signal number : 0
----- completed 5
#0 [37089ms] <- syz_failure_net_up=0x0 errno=14  /root
execute_call 0, 2019, 0, 0
execute_one loop: 0, 0, 2019
#0 [37090ms] -> syz_failure_send(0x3) 3788 /root
#0 [37090ms] <- syz_failure_send=0x0 errno=14 #1 [37085ms] <- syz_failure_sync=0x0 errno=14 cover=0  /root
execute_call 0, 0, 0, 0
execute_one loop: 0, 0, 1
 /root/glusterfs-client/dfs-0-6
execute_one inner time: 0, 3102, 0
execute_one time: 2, 3102
----- executor 3 write_call_output, size 0, pid 456, write pid:458
----- executor 3 executes write_coverage_signal cov->size 0, flag collect 1
----- executor 3 cover number : 0, signal number : 0
----- completed 6
execute_one inner time: 0, 2072, 1021
execute_one time: 1, 3093
2023/01/25 20:03:51 for select break: 1
2023/01/25 20:03:51 --------- executor 3 receive reply, reply.done 1
2023/01/25 20:03:51 wait for executor 2's reply
----- executor 1 executes write_coverage_signal cov->size 1217, flag collect 1
----- executor 0 executes write_coverage_signal cov->size 1217, flag collect 1
----- executor 2 executes write_coverage_signal cov->size 693, flag collect 1
----- executor 0 cover number : 289, signal number : 332
----- executor 1 cover number : 289, signal number : 332
----- executor 0 executes write_coverage_signal cov->size 9, flag collect 1
----- executor 0 cover number : 3, signal number : 4
----- executor 0 executes write_coverage_signal cov->size 1105, flag collect 1
----- executor 0 cover number : 371, signal number : 360
----- executor 2 cover number : 275, signal number : 314
----- executor 1 executes write_coverage_signal cov->size 9, flag collect 1
----- executor 2 executes write_coverage_signal cov->size 9, flag collect 1
----- executor 0 executes write_coverage_signal cov->size 9, flag collect 1
----- executor 0 cover number : 3, signal number : 0
----- executor 0 executes write_coverage_signal cov->size 13319, flag collect 1
----- executor 1 cover number : 3, signal number : 4
----- executor 2 cover number : 3, signal number : 4
----- executor 1 executes write_coverage_signal cov->size 770, flag collect 1
----- executor 2 executes write_coverage_signal cov->size 342, flag collect 1
----- executor 1 cover number : 255, signal number : 226
----- executor 2 cover number : 228, signal number : 166
----- executor 1 executes write_coverage_signal cov->size 9, flag collect 1
----- executor 1 cover number : 3, signal number : 0
executor 2 userspace cover_cnt 3
executor 1 userspace cover_cnt 4
----- executor 0 cover number : 1048, signal number : 1101
----- executor 0 executes write_coverage_signal cov->size 703, flag collect 1
write_metadata
------ execute 3 reply_execute finished
time breakdown 3: 96, 3096, 0
----- executor 0 cover number : 403, signal number : 1
----- executor 0 executes write_coverage_signal cov->size 9999, flag collect 1
write_metadata
------ execute 1 reply_execute finished
time breakdown 1: 82, 3111, 0
2023/01/25 20:03:51 for select break: 1
2023/01/25 20:03:51 --------- executor 2 receive reply, reply.done 1
----- executor 0 cover number : 1500, signal number : 1726
----- executor 0 executes write_coverage_signal cov->size 34, flag collect 1
----- executor 0 cover number : 30, signal number : 13
2023/01/25 20:03:51 wait for executor 1's reply
2023/01/25 20:03:51 for select break: 1
2023/01/25 20:03:51 --------- executor 1 receive reply, reply.done 1
2023/01/25 20:03:51 wait for executor 0's reply
----- executor 0 executes write_coverage_signal cov->size 13392, flag collect 1
write_metadata
------ execute 2 reply_execute finished
time breakdown 2: 81, 3112, 0
2023/01/25 20:03:51 for select break: 1
2023/01/25 20:03:51 --------- executor 0 receive reply, reply.done 1
----- executor 0 cover number : 1087, signal number : 1111
----- executor 0 executes write_coverage_signal cov->size 729, flag collect 1
----- executor 0 cover number : 376, signal number : 8
----- executor 0 executes write_coverage_signal cov->size 14362, flag collect 1
----- executor 0 cover number : 1489, signal number : 785
----- executor 0 executes write_coverage_signal cov->size 10907, flag collect 1
----- executor 0 cover number : 1912, signal number : 1185
executor 0 userspace cover_cnt 12
2023/01/25 20:03:51 ------ all executors finish execution
2023/01/25 20:03:51 exec time: 3193
2023/01/25 20:03:51 ----- PS len: 4
2023/01/25 20:03:51 [Kernel] executor 3 has 6 replies
2023/01/25 20:03:51 ----- [Userspace] executor 0 has 12 replies
2023/01/25 20:03:51 ----- [Userspace] executor 1 has 4 replies
2023/01/25 20:03:51 ------- fuzzer executor 0 receive 332 signal and 289 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 1 receive 332 signal and 289 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 0 receive 4 signal and 3 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 1 receive 4 signal and 3 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 0 receive 360 signal and 371 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 0 receive 0 signal and 3 cover from userspace component
2023/01/25 20:03:51 ----- [Userspace] executor 2 has 3 replies
2023/01/25 20:03:51 ------- fuzzer executor 2 receive 314 signal and 275 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 2 receive 4 signal and 3 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 0 receive 1101 signal and 1048 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 2 receive 166 signal and 228 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 1 receive 226 signal and 255 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 1 receive 0 signal and 3 cover from userspace component
2023/01/25 20:03:51 fuzzer receive 1579 signal and 1278 cover from kernel component
2023/01/25 20:03:51 fuzzer receive 0 signal and 0 cover from kernel component
2023/01/25 20:03:51 fuzzer receive 658 signal and 1064 cover from kernel component
2023/01/25 20:03:51 fuzzer receive 0 signal and 0 cover from kernel component
2023/01/25 20:03:51 fuzzer receive 0 signal and 0 cover from kernel component
2023/01/25 20:03:51 fuzzer receive 0 signal and 0 cover from kernel component
2023/01/25 20:03:51 ------- fuzzer executor 0 receive 1 signal and 403 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 0 receive 1726 signal and 1500 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 0 receive 13 signal and 30 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 0 receive 1111 signal and 1087 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 0 receive 8 signal and 376 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 0 receive 785 signal and 1489 cover from userspace component
2023/01/25 20:03:51 ------- fuzzer executor 0 receive 1185 signal and 1912 cover from userspace component
write_metadata
------ execute 0 reply_execute finished
time breakdown 0: 81, 3121, 0
2023/01/25 20:03:51 fsMds: [map[] map[] map[] map[]]
2023/01/25 20:03:51 result hanged=false: 
2023/01/25 20:03:51 mutate testcase with failures
2023/01/25 20:03:51 ----- mutateArg()
2023/01/25 20:03:51 ----- insertCall()
2023/01/25 20:03:51 ----- generateCall 4128 write$binfmt_misc write$binfmt_misc
2023/01/25 20:03:51 ----- insertCall()
2023/01/25 20:03:51 ----- generateCall 3675 setxattr$trusted_overlay_origin setxattr$trusted_overlay_origin
2023/01/25 20:03:51 ----- insertCall()
2023/01/25 20:03:51 ----- generateCall 2343 link link
2023/01/25 20:03:51 ----- mutateArg()
2023/01/25 20:03:51 #0: mutated
2023/01/25 20:03:51 HasCrashFail: false, .HasNetFail: false
2023/01/25 20:03:51 before return in CmpProgs, HasNetFail: false, HasCrashFail: false
symc3 prog: v0[] = "./file0";
v1[] = "./file0";
v3[] = "./file0";
v4[] = "./file0";
v5[100];
v6[100];
v7[] = "{syz0, "d26fce245afa64e11e8ef050543c91bed6e428592bf8ad6c95f63e5f2f037732947e78816b1d31c2f0d2999a8161b93adc44e96cbd46936f60e9ea7f41e4422ed413a39bc6a96fb914e337cde1944fd9bcd5aa18135ab44eaa4435a620008a2a5e91dc44acb308875fd3e2faadd6904a098b5ec32f55102d18"}";

syscall(SYS_link, v0, v1);
v2 = syscall(SYS_open, v3, 577, 64);
syscall(SYS_ftruncate, v2, 0);
syscall(SYS_setxattr, v4, v5, v6, 2, 2);
syscall(SYS_write, v2, v7, 125);

2023/01/25 20:03:51 prog length: 5
2023/01/25 20:03:51 HasCrashFail:false HasNetFail:false
20:03:51 ---executing program 0:
---
---
---
link(&(0x7f0000000180)='./file0\x00', &(0x7f00000001c0)='./file0\x00')
r0 = open(&(0x7f0000000000)='./file0\x00', 0x241, 0x40)
ftruncate(r0, 0x0)
setxattr$trusted_overlay_origin(&(0x7f00000000c0)='./file0\x00', &(0x7f0000000100), &(0x7f0000000140), 0x2, 0x2)
write$binfmt_misc(r0, &(0x7f0000000040)={'syz0', "d26fce245afa64e11e8ef050543c91bed6e428592bf8ad6c95f63e5f2f037732947e78816b1d31c2f0d2999a8161b93adc44e96cbd46936f60e9ea7f41e4422ed413a39bc6a96fb914e337cde1944fd9bcd5aa18135ab44eaa4435a620008a2a5e91dc44acb308875fd3e2faadd6904a098b5ec32f55102d18"}, 0x7d)
---

end of program
2023/01/25 20:03:51 wait for executor 3's reply
symc3 prog: v0[] = "./file0";
v1[] = "./file0";
v3[] = "./file0";
v4[] = "./file0";
v5[100];
v6[100];
v7[] = "{syz0, "d26fce245afa64e11e8ef050543c91bed6e428592bf8ad6c95f63e5f2f037732947e78816b1d31c2f0d2999a8161b93adc44e96cbd46936f60e9ea7f41e4422ed413a39bc6a96fb914e337cde1944fd9bcd5aa18135ab44eaa4435a620008a2a5e91dc44acb308875fd3e2faadd6904a098b5ec32f55102d18"}";

syscall(SYS_link, v0, v1);
v2 = syscall(SYS_open, v3, 577, 64);
syscall(SYS_ftruncate, v2, 0);
syscall(SYS_setxattr, v4, v5, v6, 2, 2);
syscall(SYS_write, v2, v7, 125);

----- executor 0 receive testcase
----- executor 3 receive testcase
executor 3: prog_data_offset 1320, prog_size 992
----- executor 1 receive testcase
executor 1: prog_data_offset 1304, prog_size 8
[37116ms] exec opts: executor=1 procid=0 threaded=0 collide=0 cover=0 extra-cover=1 comps=0 dedup=1 timeouts=50/500000/1 prog=8 filter=0
----- executor 2 receive testcase
executor 2: prog_data_offset 1312, prog_size 8
[37101ms] exec opts: executor=2 procid=0 threaded=0 collide=0 cover=0 extra-cover=1 comps=0 dedup=1 timeouts=50/500000/1 prog=8 filter=0
[37111ms] exec opts: executor=3 procid=0 threaded=1 collide=0 cover=0 extra-cover=1 comps=0 dedup=1 timeouts=50/500000/1 prog=992 filter=0
remove dir: /root/glusterfs-client/dfs-0-6
executor 0: prog_data_offset 1296, prog_size 8
[37125ms] exec opts: executor=0 procid=0 threaded=0 collide=0 cover=0 extra-cover=1 comps=0 dedup=1 timeouts=50/500000/1 prog=8 filter=0
opendir(/root/glusterfs-client/dfs-0-6) failedremove dir time 0
-----finish removing dir
