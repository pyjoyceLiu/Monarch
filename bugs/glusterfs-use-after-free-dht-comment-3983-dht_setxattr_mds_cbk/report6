#0 [12608ms] <- syz_failure_recv=0x0 errno=14  /root
execute_call 0, 316, 0, 0
execute_one loop: 0, 0, 316
#0 [12608ms] -> syz_failure_net_up() 3786 /root
=================================================================
==411==ERROR: AddressSanitizer: heap-use-after-free on address 0x6210001d1834 at pc 0x7fffeeff13c6 bp 0x7fffefa6f620 sp 0x7fffefa6f610
READ of size 4 at 0x6210001d1834 thread T7
    #0 0x7fffeeff13c5 in dht_setxattr_mds_cbk /root/glusterfs/xlators/cluster/dht/src/dht-common.c:3983
    #1 0x7fffef1e96b1 in client4_0_setxattr_cbk /root/glusterfs/xlators/protocol/client/src/client-rpc-fops_v2.c:865
    #2 0x7ffff721ffca in rpc_clnt_handle_reply /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:723
    #3 0x7ffff721ffca in rpc_clnt_notify /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:890
    #4 0x7ffff7219983 in rpc_transport_notify /root/glusterfs/rpc/rpc-lib/src/rpc-transport.c:521
    #5 0x7ffff03405a6 in socket_event_poll_in_async /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2358
    #6 0x7ffff0350b39 in gf_async ../../../../libglusterfs/src/glusterfs/async.h:187
    #7 0x7ffff0350b39 in socket_event_poll_in /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2399
    #8 0x7ffff0350b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2790
    #9 0x7ffff0350b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2710
    #10 0x7ffff73fa6c0 in event_dispatch_epoll_handler /root/glusterfs/libglusterfs/src/event-epoll.c:631
    #11 0x7ffff73fa6c0 in event_dispatch_epoll_worker /root/glusterfs/libglusterfs/src/event-epoll.c:742
    #12 0x7ffff71bf608 in start_thread /build/glibc-YYA7BZ/glibc-2.31/nptl/pthread_create.c:477
    #13 0x7ffff70e4102 in __clone (/lib/x86_64-linux-gnu/libc.so.6+0x122102)

0x6210001d1834 is located 1844 bytes inside of 4164-byte region [0x6210001d1100,0x6210001d2144)
freed by thread T7 here:
    #0 0x7ffff769a7cf in __interceptor_free (/lib/x86_64-linux-gnu/libasan.so.5+0x10d7cf)
    #1 0x7ffff7355e19 in __gf_free /root/glusterfs/libglusterfs/src/mem-pool.c:383
    #2 0x7fffeef71acd in dht_local_wipe /root/glusterfs/xlators/cluster/dht/src/dht-helper.c:805
    #3 0x7fffeef71acd in dht_local_wipe /root/glusterfs/xlators/cluster/dht/src/dht-helper.c:713
    #4 0x7fffef05d734 in dht_setxattr_non_mds_cbk /root/glusterfs/xlators/cluster/dht/src/dht-common.c:3886
    #5 0x7fffef1e96b1 in client4_0_setxattr_cbk /root/glusterfs/xlators/protocol/client/src/client-rpc-fops_v2.c:865
    #6 0x7fffef1995ac in client_submit_request /root/glusterfs/xlators/protocol/client/src/client.c:288
    #7 0x7fffef1cd175 in client4_0_setxattr /root/glusterfs/xlators/protocol/client/src/client-rpc-fops_v2.c:4171
    #8 0x7fffef19757f in client_setxattr /root/glusterfs/xlators/protocol/client/src/client.c:1259
    #9 0x7fffeefed8cb in dht_setxattr_mds_cbk /root/glusterfs/xlators/cluster/dht/src/dht-common.c:3965
    #10 0x7fffef1e96b1 in client4_0_setxattr_cbk /root/glusterfs/xlators/protocol/client/src/client-rpc-fops_v2.c:865
    #11 0x7ffff721ffca in rpc_clnt_handle_reply /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:723
    #12 0x7ffff721ffca in rpc_clnt_notify /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:890
    #13 0x7ffff7219983 in rpc_transport_notify /root/glusterfs/rpc/rpc-lib/src/rpc-transport.c:521
    #14 0x7ffff03405a6 in socket_event_poll_in_async /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2358
    #15 0x7ffff0350b39 in gf_async ../../../../libglusterfs/src/glusterfs/async.h:187
    #16 0x7ffff0350b39 in socket_event_poll_in /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2399
    #17 0x7ffff0350b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2790
    #18 0x7ffff0350b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2710
    #19 0x7ffff73fa6c0 in event_dispatch_epoll_handler /root/glusterfs/libglusterfs/src/event-epoll.c:631
    #20 0x7ffff73fa6c0 in event_dispatch_epoll_worker /root/glusterfs/libglusterfs/src/event-epoll.c:742
    #21 0x7ffff71bf608 in start_thread /build/glibc-YYA7BZ/glibc-2.31/nptl/pthread_create.c:477

previously allocated by thread T8 here:
    #0 0x7ffff769adc6 in calloc (/lib/x86_64-linux-gnu/libasan.so.5+0x10ddc6)
    #1 0x7ffff7355226 in __gf_calloc /root/glusterfs/libglusterfs/src/mem-pool.c:177
    #2 0x7fffeef7db19 in dht_local_init /root/glusterfs/xlators/cluster/dht/src/dht-helper.c:815
    #3 0x7fffef06cc91 in dht_setxattr /root/glusterfs/xlators/cluster/dht/src/dht-common.c:5796
    #4 0x7ffff747be59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #5 0x7ffff747be59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #6 0x7ffff747be59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #7 0x7fffeeeb4f21 in ob_setxattr /root/glusterfs/xlators/performance/open-behind/src/open-behind.c:777
    #8 0x7fffeeeb4f21 in ob_setxattr /root/glusterfs/xlators/performance/open-behind/src/open-behind.c:768
    #9 0x7ffff747be59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #10 0x7fffeee41023 in mdc_setxattr /root/glusterfs/xlators/performance/md-cache/src/md-cache.c:2403
    #11 0x7ffff74d1bf0 in default_setxattr_resume /root/glusterfs/libglusterfs/src/defaults.c:1745
    #12 0x7ffff731dfb6 in call_resume_wind /root/glusterfs/libglusterfs/src/call-stub.c:2073
    #13 0x7ffff734d8f4 in call_resume /root/glusterfs/libglusterfs/src/call-stub.c:2390
    #14 0x7fffeee168bc in iot_worker /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:227
    #15 0x7ffff71bf608 in start_thread /build/glibc-YYA7BZ/glibc-2.31/nptl/pthread_create.c:477

Thread T7 created by T0 here:
    #0 0x7ffff75c7805 in pthread_create (/lib/x86_64-linux-gnu/libasan.so.5+0x3a805)
    #1 0x7ffff72f8b97 in gf_thread_vcreate /root/glusterfs/libglusterfs/src/common-utils.c:3261
    #2 0x7ffff730a28d in gf_thread_create /root/glusterfs/libglusterfs/src/common-utils.c:3284
    #3 0x7ffff73f8af2 in event_dispatch_epoll /root/glusterfs/libglusterfs/src/event-epoll.c:797
    #4 0x7ffff7353f89 in gf_event_dispatch /root/glusterfs/libglusterfs/src/event.c:115
    #5 0x7ffff7461b7f in gf_io_main /root/glusterfs/libglusterfs/src/gf-io.c:431
    #6 0x7ffff7461b7f in gf_io_run /root/glusterfs/libglusterfs/src/gf-io.c:516
    #7 0x55555556c37a in main /root/glusterfs/glusterfsd/src/glusterfsd.c:2774
    #8 0x7ffff6fe90b2 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x270b2)

Thread T8 created by T7 here:
    #0 0x7ffff75c7805 in pthread_create (/lib/x86_64-linux-gnu/libasan.so.5+0x3a805)
    #1 0x7ffff72f8b97 in gf_thread_vcreate /root/glusterfs/libglusterfs/src/common-utils.c:3261
    #2 0x7ffff730a28d in gf_thread_create /root/glusterfs/libglusterfs/src/common-utils.c:3284
    #3 0x7fffeee15ace in __iot_workers_scale /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:830
    #4 0x7fffeee1dd62 in iot_workers_scale /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:853
    #5 0x7fffeee1dd62 in init /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:1251
    #6 0x7ffff72e5208 in __xlator_init /root/glusterfs/libglusterfs/src/xlator.c:610
    #7 0x7ffff72e5208 in xlator_init /root/glusterfs/libglusterfs/src/xlator.c:635
    #8 0x7ffff7378672 in glusterfs_graph_init /root/glusterfs/libglusterfs/src/graph.c:474
    #9 0x7ffff737971b in glusterfs_graph_activate /root/glusterfs/libglusterfs/src/graph.c:823
    #10 0x555555573a4e in glusterfs_process_volfp /root/glusterfs/glusterfsd/src/glusterfsd.c:2493
    #11 0x555555584675 in mgmt_getspec_cbk /root/glusterfs/glusterfsd/src/glusterfsd-mgmt.c:2444
    #12 0x7ffff721ffca in rpc_clnt_handle_reply /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:723
    #13 0x7ffff721ffca in rpc_clnt_notify /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:890
    #14 0x7ffff7219983 in rpc_transport_notify /root/glusterfs/rpc/rpc-lib/src/rpc-transport.c:521
    #15 0x7ffff03405a6 in socket_event_poll_in_async /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2358
    #16 0x7ffff0350b39 in gf_async ../../../../libglusterfs/src/glusterfs/async.h:187
    #17 0x7ffff0350b39 in socket_event_poll_in /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2399
    #18 0x7ffff0350b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2790
    #19 0x7ffff0350b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2710
    #20 0x7ffff73fa6c0 in event_dispatch_epoll_handler /root/glusterfs/libglusterfs/src/event-epoll.c:631
    #21 0x7ffff73fa6c0 in event_dispatch_epoll_worker /root/glusterfs/libglusterfs/src/event-epoll.c:742
    #22 0x7ffff71bf608 in start_thread /build/glibc-YYA7BZ/glibc-2.31/nptl/pthread_create.c:477

SUMMARY: AddressSanitizer: heap-use-after-free /root/glusterfs/xlators/cluster/dht/src/dht-common.c:3983 in dht_setxattr_mds_cbk
Shadow bytes around the buggy address:
  0x0c42800322b0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c42800322c0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c42800322d0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c42800322e0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c42800322f0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
=>0x0c4280032300: fd fd fd fd fd fd[fd]fd fd fd fd fd fd fd fd fd
  0x0c4280032310: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c4280032320: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c4280032330: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c4280032340: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c4280032350: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07 
  Heap left redzone:       fa
  Freed heap region:       fd
  Stack left redzone:      f1
  Stack mid redzone:       f2
  Stack right redzone:     f3
  Stack after return:      f5
  Stack use after scope:   f8
  Global redzone:          f9
  Global init order:       f6
  Poisoned by user:        f7
  Container overflow:      fc
  Array cookie:            ac
  Intra object redzone:    bb
  ASan internal:           fe
  Left alloca redzone:     ca
  Right alloca redzone:    cb
  Shadow gap:              cc
==411==ABORTING
execute_one loop: 0, 0, 1001
#0 [14610ms] <- syz_failure_sync=0x0 errno=14 cover=0  /root/glusterfs-client/dfs-0-5
#0 [14614ms] <- syz_failure_net_up=0x0 errno=14  /root
execute_call 0, 2006, 0, 0
execute_one loop: 0, 0, 2006
#0 [14614ms] -> syz_failure_send(0x1----- executor 3 write_call_output, size 0, pid 439, write pid:440
----- executor 3 executes write_coverage_signal cov->size 0, flag collect 0
----- executor 3 signal number : 0
----- completed 7
) 3788 /root
#0 [14614ms] <- syz_failure_send=0x0 errno=14  /root
execute_call 0, 0, 0, 0
execute_one loop: 0, 0, 0
execute_one inner time: 0, 2332, 0
execute_one time: 1, 2332
execute_one inner time: 0, 1325, 1006
execute_one time: 0, 2331
write_metadata
------ execute 3 reply_execute finished
time breakdown 3: 41, 2334, 0
2023/01/26 06:02:50 for select break: 1
2023/01/26 06:02:50 --------- executor 3 receive reply, reply.done 1
2023/01/26 06:02:50 wait for executor 2's reply
executor 0 userspace cover_cnt 0
----- executor 1 executes write_coverage_signal cov->size 577, flag collect 0
----- executor 1 signal number : 183
----- executor 1 executes write_coverage_signal cov->size 1781, flag collect 0
----- executor 1 signal number : 737
----- executor 1 executes write_coverage_signal cov->size 1196, flag collect 0
----- executor 1 signal number : 165
----- executor 1 executes write_coverage_signal cov->size 2047, flag collect 0
----- executor 1 signal number : 310
----- executor 1 executes write_coverage_signal cov->size 1362, flag collect 0
----- executor 1 signal number : 4
----- executor 1 executes write_coverage_signal cov->size 8067, flag collect 0
----- executor 1 signal number : 1370
----- executor 1 executes write_coverage_signal cov->size 3075, flag collect 0
----- executor 1 signal number : 568
----- executor 1 executes write_coverage_signal cov->size 3082, flag collect 0
----- executor 1 signal number : 689
----- executor 1 executes write_coverage_signal cov->size 3183, flag collect 0
----- executor 1 signal number : 85
----- executor 1 executes write_coverage_signal cov->size 2044, flag collect 0
----- executor 1 signal number : 212
----- executor 1 executes write_coverage_signal cov->size 14013, flag collect 0
----- executor 1 signal number : 1298
----- executor 1 executes write_coverage_signal cov->size 319, flag collect 0
----- executor 1 signal number : 55
----- executor 1 executes write_coverage_signal cov->size 32765, flag collect 0
----- executor 1 signal number : 102
----- executor 1 executes write_coverage_signal cov->size 17, flag collect 0
----- executor 1 signal number : 11
----- executor 1 executes write_coverage_signal cov->size 178, flag collect 0
----- executor 1 signal number : 15
----- executor 1 executes write_coverage_signal cov->size 5, flag collect 0
----- executor 1 signal number : 5
----- executor 1 executes write_coverage_signal cov->size 5, flag collect 0
----- executor 1 signal number : 0
----- executor 1 executes write_coverage_signal cov->size 4, flag collect 0
----- executor 1 signal number : 4
----- executor 1 executes write_coverage_signal cov->size 1454, flag collect 0
----- executor 1 signal number : 173
----- executor 1 executes write_coverage_signal cov->size 463, flag collect 0
----- executor 1 signal number : 15
executor 1 userspace cover_cnt 20
write_metadata
------ execute 0 reply_execute finished
time breakdown 0: 35, 2340, 1
write_metadata
------ execute 1 reply_execute finished
time breakdown 1: 31, 2343, 0
2023/01/26 06:02:50 for select break: 1
2023/01/26 06:02:50 --------- executor 2 receive reply, reply.done 1
2023/01/26 06:02:50 wait for executor 1's reply
2023/01/26 06:02:50 for select break: 1
2023/01/26 06:02:50 --------- executor 1 receive reply, reply.done 1
2023/01/26 06:02:50 wait for executor 0's reply
2023/01/26 06:02:50 for select break: 1
2023/01/26 06:02:50 --------- executor 0 receive reply, reply.done 1
2023/01/26 06:02:50 ------ all executors finish execution
2023/01/26 06:02:50 exec time: 2378
2023/01/26 06:02:50 ----- PS len: 4
2023/01/26 06:02:50 [Kernel] executor 3 has 7 replies
2023/01/26 06:02:50 fuzzer receive 0 signal and 0 cover from kernel component
2023/01/26 06:02:50 fuzzer receive 0 signal and 0 cover from kernel component
2023/01/26 06:02:50 fuzzer receive 1583 signal and 0 cover from kernel component
2023/01/26 06:02:50 fuzzer receive 0 signal and 0 cover from kernel component
2023/01/26 06:02:50 fuzzer receive 662 signal and 0 cover from kernel component
2023/01/26 06:02:50 fuzzer receive 176 signal and 0 cover from kernel component
2023/01/26 06:02:50 fuzzer receive 0 signal and 0 cover from kernel component
2023/01/26 06:02:50 ----- [Userspace] executor 0 has 0 replies
2023/01/26 06:02:50 ----- [Userspace] executor 1 has 20 replies
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 183 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 737 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 165 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 310 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 4 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 1370 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 568 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 689 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 85 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 212 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 1298 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 55 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 102 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 11 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 15 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 5 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 0 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 4 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 173 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 1 receive 15 signal and 0 cover from userspace component
----- executor 2 executes write_coverage_signal cov->size 548, flag collect 0
----- executor 2 signal number : 309
----- executor 2 executes write_coverage_signal cov->size 9, flag collect 0
----- executor 2 signal number : 4
----- executor 2 executes write_coverage_signal cov->size 2301, flag collect 0
----- executor 2 signal number : 692
----- executor 2 executes write_coverage_signal cov->size 6, flag collect 0
----- executor 2 signal number : 0
----- executor 2 executes write_coverage_signal cov->size 5560, flag collect 0
----- executor 2 signal number : 400
----- executor 2 executes write_coverage_signal cov->size 8973, flag collect 0
----- executor 2 signal number : 425
----- executor 2 executes write_coverage_signal cov->size 12794, flag collect 0
----- executor 2 signal number : 1713
----- executor 2 executes write_coverage_signal cov->size 17, flag collect 0
----- executor 2 signal number : 16
----- executor 2 executes write_coverage_signal cov->size 9434, flag collect 0
----- executor 2 signal number : 875
----- executor 2 executes write_coverage_signal cov->size 10654, flag collect 0
----- executor 2 signal number : 1445
----- executor 2 executes write_coverage_signal cov->size 6451, flag collect 0
----- executor 2 signal number : 488
----- executor 2 executes write_coverage_signal cov->size 14973, flag collect 0
----- executor 2 signal number : 690
executor 2 userspace cover_cnt 12
2023/01/26 06:02:50 ----- [Userspace] executor 2 has 12 replies
2023/01/26 06:02:50 ------- fuzzer executor 2 receive 309 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 2 receive 4 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 2 receive 692 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 2 receive 0 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 2 receive 400 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 2 receive 425 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 2 receive 1713 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 2 receive 16 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 2 receive 875 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 2 receive 1445 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 2 receive 488 signal and 0 cover from userspace component
2023/01/26 06:02:50 ------- fuzzer executor 2 receive 690 signal and 0 cover from userspace component
2023/01/26 06:02:50 fsMds: [map[] map[] map[] map[]]
2023/01/26 06:02:50 result hanged=false: 
2023/01/26 06:02:50 before return in CmpProgs, HasNetFail: false, HasCrashFail: false
symc3 prog: v0[] = "./file0";
v1[] = "./file0";
v2[100];
v3[] = "test";
v4[] = "./file0";
v5[100];

syscall(SYS_mkdir, v0, 511);
syscall(SYS_setxattr, v1, v2, v3, 4, 0);
syscall(SYS_removexattr, v4, v5);

2023/01/26 06:02:50 prog length: 6
2023/01/26 06:02:50 prog length: 6
2023/01/26 06:02:50 prog length: 7
2023/01/26 06:02:50 error in logProgram
2023/01/26 06:02:50 HasCrashFail:false HasNetFail:false
06:02:50 ---executing program 0:
syz_failure_recv(0x0)
syz_failure_net_down(&(0x7f0000000000)='iptables -A INPUT -s 192.168.0.51 192.168.0.53 192.168.0.53 192.168.0.53  -j DROP; iptables -A OUTPUT -d 192.168.0.51 192.168.0.53 192.168.0.53 192.168.0.53  -j DROP')
syz_failure_send(0x0)
syz_failure_recv(0x1)
syz_failure_net_up()
syz_failure_send(0x1)
---
syz_failure_recv(0x2)
syz_failure_down()
syz_failure_send(0x2)
syz_failure_recv(0x3)
syz_failure_up()
syz_failure_send(0x3)
---
---
syz_failure_sync(0x0, 0x3)
syz_failure_sync(0x2, 0x3)
mkdir(&(0x7f0000000040)='./file0\x00', 0x1ff)
syz_failure_sync(0x3, 0x3)
setxattr$user(&(0x7f0000000080)='./file0\x00', &(0x7f00000000c0), &(0x7f0000000100)='test\x00', 0x4, 0x0)
removexattr(&(0x7f0000000140)='./file0\x00', &(0x7f00000000c0))
syz_failure_sync(0x1, 0x3)
---

end of program
2023/01/26 06:02:50 wait for executor 3's reply
symc3 prog: v0[] = "./file0";
v1[] = "./file0";
v2[100];
v3[] = "test";
v4[] = "./file0";
v5[100];

syscall(SYS_mkdir, v0, 511);
syscall(SYS_setxattr, v1, v2, v3, 4, 0);
syscall(SYS_removexattr, v4, v5);

----- executor 0 receive testcase
----- executor 1 receive testcase
executor 1: prog_data_offset 1768, prog_size 248
----- executor 3 receive testcase
executor 3: prog_data_offset 2024, prog_size 792
[14630ms] exec opts: executor=3 procid=0 threaded=1 collide=0 cover=1 extra-cover=1 comps=0 dedup=1 timeouts=50/500000/1 prog=792 filter=0
remove dir: /root/glusterfs-client/dfs-0-5
executor 0: prog_data_offset 1296, prog_size 472
opendir(/root/glusterfs-client/dfs-0-5) failedremove dir time 0
-----finish removing dir
[14627ms] exec opts: executor=1 procid=0 threaded=0 collide=0 cover=1 extra-cover=1 comps=0 dedup=1 timeouts=50/500000/1 prog=248 filter=0
[14634ms] exec opts: executor=0 procid=0 threaded=0 collide=0 cover=1 extra-cover=1 comps=0 dedup=1 timeouts=50/500000/1 prog=472 filter=0
write_metadata
------ execute 2 reply_execute finished
time breakdown 2: 35, 2348, 0
----- executor 2 receive testcase
executor 2: prog_data_offset 2016, prog_size 8
[14627ms] exec opts: executor=2 procid=0 threaded=0 collide=0 cover=1 extra-cover=1 comps=0 dedup=1 timeouts=50/500000/1 prog=8 filter=0
