cover_reset in execute_call
executor 3 waits for recv msg
Node-3:/root/daemon-log.417
) 3792 /root
=================================================================
==417==ERROR: AddressSanitizer: heap-use-after-free on address 0x62100027cc34 at pc 0x7fffef061907 bp 0x7fffeed2e7e0 sp 0x7fffeed2e7d0
READ of size 4 at 0x62100027cc34 thread T8
    #0 0x7fffef061906 in dht_dir_common_set_remove_xattr /root/glusterfs/xlators/cluster/dht/src/dht-common.c:5494
    #1 0x7fffef0763d9 in dht_setxattr /root/glusterfs/xlators/cluster/dht/src/dht-common.c:5974
    #2 0x7ffff7481e59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #3 0x7ffff7481e59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #4 0x7ffff7481e59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #5 0x7fffeeebaf21 in ob_setxattr /root/glusterfs/xlators/performance/open-behind/src/open-behind.c:777
    #6 0x7fffeeebaf21 in ob_setxattr /root/glusterfs/xlators/performance/open-behind/src/open-behind.c:768
    #7 0x7ffff7481e59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #8 0x7fffeee47023 in mdc_setxattr /root/glusterfs/xlators/performance/md-cache/src/md-cache.c:2403
    #9 0x7ffff74d7bf0 in default_setxattr_resume /root/glusterfs/libglusterfs/src/defaults.c:1745
    #10 0x7ffff7323fb6 in call_resume_wind /root/glusterfs/libglusterfs/src/call-stub.c:2073
    #11 0x7ffff73538f4 in call_resume /root/glusterfs/libglusterfs/src/call-stub.c:2390
    #12 0x7fffeee1c8bc in iot_worker /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:227
    #13 0x7ffff71c5608 in start_thread /build/glibc-YYA7BZ/glibc-2.31/nptl/pthread_create.c:477
    #14 0x7ffff70ea102 in __clone (/lib/x86_64-linux-gnu/libc.so.6+0x122102)

0x62100027cc34 is located 1844 bytes inside of 4164-byte region [0x62100027c500,0x62100027d544)
freed by thread T7 here:
    #0 0x7ffff76a07cf in __interceptor_free (/lib/x86_64-linux-gnu/libasan.so.5+0x10d7cf)
    #1 0x7ffff735be19 in __gf_free /root/glusterfs/libglusterfs/src/mem-pool.c:383
    #2 0x7fffeef77acd in dht_local_wipe /root/glusterfs/xlators/cluster/dht/src/dht-helper.c:805
    #3 0x7fffeef77acd in dht_local_wipe /root/glusterfs/xlators/cluster/dht/src/dht-helper.c:713
    #4 0x7fffeeff9070 in dht_err_cbk /root/glusterfs/xlators/cluster/dht/src/dht-common.c:3742
    #5 0x7fffef1ef6b1 in client4_0_setxattr_cbk /root/glusterfs/xlators/protocol/client/src/client-rpc-fops_v2.c:865
    #6 0x7ffff7225fca in rpc_clnt_handle_reply /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:723
    #7 0x7ffff7225fca in rpc_clnt_notify /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:890
    #8 0x7ffff721f983 in rpc_transport_notify /root/glusterfs/rpc/rpc-lib/src/rpc-transport.c:521
    #9 0x7ffff03465a6 in socket_event_poll_in_async /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2358
    #10 0x7ffff0356b39 in gf_async ../../../../libglusterfs/src/glusterfs/async.h:187
    #11 0x7ffff0356b39 in socket_event_poll_in /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2399
    #12 0x7ffff0356b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2790
    #13 0x7ffff0356b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2710
    #14 0x7ffff74006c0 in event_dispatch_epoll_handler /root/glusterfs/libglusterfs/src/event-epoll.c:631
    #15 0x7ffff74006c0 in event_dispatch_epoll_worker /root/glusterfs/libglusterfs/src/event-epoll.c:742
    #16 0x7ffff71c5608 in start_thread /build/glibc-YYA7BZ/glibc-2.31/nptl/pthread_create.c:477

previously allocated by thread T8 here:
    #0 0x7ffff76a0dc6 in calloc (/lib/x86_64-linux-gnu/libasan.so.5+0x10ddc6)
    #1 0x7ffff735b226 in __gf_calloc /root/glusterfs/libglusterfs/src/mem-pool.c:177
    #2 0x7fffeef83b19 in dht_local_init /root/glusterfs/xlators/cluster/dht/src/dht-helper.c:815
    #3 0x7fffef072c91 in dht_setxattr /root/glusterfs/xlators/cluster/dht/src/dht-common.c:5796
    #4 0x7ffff7481e59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #5 0x7ffff7481e59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #6 0x7ffff7481e59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #7 0x7fffeeebaf21 in ob_setxattr /root/glusterfs/xlators/performance/open-behind/src/open-behind.c:777
    #8 0x7fffeeebaf21 in ob_setxattr /root/glusterfs/xlators/performance/open-behind/src/open-behind.c:768
    #9 0x7ffff7481e59 in default_setxattr /root/glusterfs/libglusterfs/src/defaults.c:2443
    #10 0x7fffeee47023 in mdc_setxattr /root/glusterfs/xlators/performance/md-cache/src/md-cache.c:2403
    #11 0x7ffff74d7bf0 in default_setxattr_resume /root/glusterfs/libglusterfs/src/defaults.c:1745
    #12 0x7ffff7323fb6 in call_resume_wind /root/glusterfs/libglusterfs/src/call-stub.c:2073
    #13 0x7ffff73538f4 in call_resume /root/glusterfs/libglusterfs/src/call-stub.c:2390
    #14 0x7fffeee1c8bc in iot_worker /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:227
    #15 0x7ffff71c5608 in start_thread /build/glibc-YYA7BZ/glibc-2.31/nptl/pthread_create.c:477

Thread T8 created by T6 here:
    #0 0x7ffff75cd805 in pthread_create (/lib/x86_64-linux-gnu/libasan.so.5+0x3a805)
    #1 0x7ffff72feb97 in gf_thread_vcreate /root/glusterfs/libglusterfs/src/common-utils.c:3261
    #2 0x7ffff731028d in gf_thread_create /root/glusterfs/libglusterfs/src/common-utils.c:3284
    #3 0x7fffeee1bace in __iot_workers_scale /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:830
    #4 0x7fffeee23d62 in iot_workers_scale /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:853
    #5 0x7fffeee23d62 in init /root/glusterfs/xlators/performance/io-threads/src/io-threads.c:1251
    #6 0x7ffff72eb208 in __xlator_init /root/glusterfs/libglusterfs/src/xlator.c:610
    #7 0x7ffff72eb208 in xlator_init /root/glusterfs/libglusterfs/src/xlator.c:635
    #8 0x7ffff737e672 in glusterfs_graph_init /root/glusterfs/libglusterfs/src/graph.c:474
    #9 0x7ffff737f71b in glusterfs_graph_activate /root/glusterfs/libglusterfs/src/graph.c:823
    #10 0x555555573a4e in glusterfs_process_volfp /root/glusterfs/glusterfsd/src/glusterfsd.c:2493
    #11 0x555555584675 in mgmt_getspec_cbk /root/glusterfs/glusterfsd/src/glusterfsd-mgmt.c:2444
    #12 0x7ffff7225fca in rpc_clnt_handle_reply /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:723
    #13 0x7ffff7225fca in rpc_clnt_notify /root/glusterfs/rpc/rpc-lib/src/rpc-clnt.c:890
    #14 0x7ffff721f983 in rpc_transport_notify /root/glusterfs/rpc/rpc-lib/src/rpc-transport.c:521
    #15 0x7ffff03465a6 in socket_event_poll_in_async /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2358
    #16 0x7ffff0356b39 in gf_async ../../../../libglusterfs/src/glusterfs/async.h:187
    #17 0x7ffff0356b39 in socket_event_poll_in /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2399
    #18 0x7ffff0356b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2790
    #19 0x7ffff0356b39 in socket_event_handler /root/glusterfs/rpc/rpc-transport/socket/src/socket.c:2710
    #20 0x7ffff74006c0 in event_dispatch_epoll_handler /root/glusterfs/libglusterfs/src/event-epoll.c:631
    #21 0x7ffff74006c0 in event_dispatch_epoll_worker /root/glusterfs/libglusterfs/src/event-epoll.c:742
    #22 0x7ffff71c5608 in start_thread /build/glibc-YYA7BZ/glibc-2.31/nptl/pthread_create.c:477

Thread T6 created by T0 here:
    #0 0x7ffff75cd805 in pthread_create (/lib/x86_64-linux-gnu/libasan.so.5+0x3a805)
    #1 0x7ffff72feb97 in gf_thread_vcreate /root/glusterfs/libglusterfs/src/common-utils.c:3261
    #2 0x7ffff731028d in gf_thread_create /root/glusterfs/libglusterfs/src/common-utils.c:3284
    #3 0x7ffff73feaf2 in event_dispatch_epoll /root/glusterfs/libglusterfs/src/event-epoll.c:797
    #4 0x7ffff7359f89 in gf_event_dispatch /root/glusterfs/libglusterfs/src/event.c:115
    #5 0x7ffff7467b7f in gf_io_main /root/glusterfs/libglusterfs/src/gf-io.c:431
    #6 0x7ffff7467b7f in gf_io_run /root/glusterfs/libglusterfs/src/gf-io.c:516
    #7 0x55555556c37a in main /root/glusterfs/glusterfsd/src/glusterfsd.c:2774
    #8 0x7ffff6fef0b2 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x270b2)

Thread T7 created by T0 here:
    #0 0x7ffff75cd805 in pthread_create (/lib/x86_64-linux-gnu/libasan.so.5+0x3a805)
    #1 0x7ffff72feb97 in gf_thread_vcreate /root/glusterfs/libglusterfs/src/common-utils.c:3261
    #2 0x7ffff731028d in gf_thread_create /root/glusterfs/libglusterfs/src/common-utils.c:3284
    #3 0x7ffff73feaf2 in event_dispatch_epoll /root/glusterfs/libglusterfs/src/event-epoll.c:797
    #4 0x7ffff7359f89 in gf_event_dispatch /root/glusterfs/libglusterfs/src/event.c:115
    #5 0x7ffff7467b7f in gf_io_main /root/glusterfs/libglusterfs/src/gf-io.c:431
    #6 0x7ffff7467b7f in gf_io_run /root/glusterfs/libglusterfs/src/gf-io.c:516
    #7 0x55555556c37a in main /root/glusterfs/glusterfsd/src/glusterfsd.c:2774
    #8 0x7ffff6fef0b2 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x270b2)

SUMMARY: AddressSanitizer: heap-use-after-free /root/glusterfs/xlators/cluster/dht/src/dht-common.c:5494 in dht_dir_common_set_remove_xattr
Shadow bytes around the buggy address:
  0x0c4280047930: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c4280047940: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c4280047950: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c4280047960: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c4280047970: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
=>0x0c4280047980: fd fd fd fd fd fd[fd]fd fd fd fd fd fd fd fd fd
  0x0c4280047990: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c42800479a0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c42800479b0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c42800479c0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c42800479d0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07 
  Heap left redzone:       fa
  Freed heap region:       fd
  Stack left redzone:      f1
  Stack mid redzone:       f2
  Stack right redzone:     f3
  Stack after return:      f5
  Stack use after scope:   f8
  Global redzone:          f9
  Global init order:       f6
  Poisoned by user:        f7
  Container overflow:      fc
  Array cookie:            ac
  Intra object redzone:    bb
  ASan internal:           fe
  Left alloca redzone:     ca
  Right alloca redzone:    cb
  Shadow gap:              cc
==417==ABORTING
Node-1:/root/daemon-log.727
==727==WARNING: ASan doesn't fully support makecontext/swapcontext functions and may produce false positives in some cases!
#0 [82752ms] <- syz_failure_sync=0x0 errno=14 cover=0  /root/glusterfs-client/dfs-0-6
----- executor 3 write_call_output, size 0, pid 444, write pid:444
----- executor 3 executes write_coverage_signal cov->size 0, flag collect 0
----- executor 3 signal number : 0
----- completed 12
execute_call 0, 6009, 0, 0
execute_one loop: 0, 0, 6009
#0 [82752ms] -> setxattr$security_smack_transmute(0x20000240, 0x20000780, 0x200007c0, 0x4, 0x0) 3670 /root/glusterfs-client/dfs-0-6
cover_reset in execute_call
#0 [82752ms] <- setxattr$security_smack_transmute=0xffffffffffffffff errno=107 cover=0  /root/glusterfs-client/dfs-0-6
----- executor 3 write_call_output, size 0, pid 444, write pid:444
----- executor 3 executes write_coverage_signal cov->size 0, flag collect 0
----- executor 3 signal number : 0
----- completed 13
execute_call 0, 1, 0, 0
execute_one loop: 0, 0, 1
#0 [82753ms] -> open$dir(0x20000040, 0x440, 0x13#0 [82764ms] <- syz_failure_up=0x0 errno=14  /root
execute_call 0, 6008, 0, 0
execute_one loop: 0, 0, 6008
#0 [82764ms] -> syz_failure_send(0x1) 3790 /root
#0 [82764ms] <- syz_failure_send=0x0 errno=14  /root
execute_call 0, 0, 0, 0
execute_one loop: 0, 0, 0
executor 0, execute_one inner time: 0, 6281, 0
execute_one time: 2, 6281
) 2459 /root/glusterfs-client/dfs-0-6
cover_reset in execute_call
#0 [82755ms] <- open$dir=0xffffffffffffffff errno=107 cover=0  /root/glusterfs-client/dfs-0-6
----- executor 3 write_call_output, size 0, pid 444, write pid:444
----- executor 3 executes write_coverage_signal cov->size 0, flag collect 0
----- executor 3 signal number : 0
----- completed 14
execute_call 0, 3, 0, 1
execute_one loop: 0, 1, 4
#0 [82757ms] -> openat(0x17, 0x20000280, 0x30401, 0x181) 2462 /root/glusterfs-client/dfs-0-6
cover_reset in execute_call
#0 [82757ms] <- openat=0xffffffffffffffff errno=20 cover=0  /root/glusterfs-client/dfs-0-6
----- executor 3 write_call_output, size 0, pid 444, write pid:444
----- executor 3 executes write_coverage_signal cov->size 0, flag collect 0
----- executor 3 signal number : 0
----- completed 15
execute_call 0, 0, 0, 0
execute_one loop: 0, 0, 0
#0 [82757ms] -> openat(0xffffffffffffffff, 0x20000580, 0x200, 0x104) 2462 /root/glusterfs-client/dfs-0-6
cover_reset in execute_call
#0 [82757ms] <- openat=0xffffffffffffffff errno=9 cover=0  /root/glusterfs-client/dfs-0-6
----- executor 3 write_call_output, size 0, pid 444, write pid:444
----- executor 3 executes write_coverage_signal cov->size 0, flag collect 0
----- executor 3 signal number : 0
----- completed 16
execute_call 0, 0, 0, 0
execute_one loop: 0, 0, 0
#0 [82757ms] -> fcntl$dupfd(0xffffffffffffffff, 0x406, 0xffffffffffffffff) 203 /root/glusterfs-client/dfs-0-6
cover_reset in execute_call
#0 [82757ms] <- fcntl$dupfd=0xffffffffffffffff errno=9 cover=0  /root/glusterfs-client/dfs-0-6
----- executor 3 write_call_output, size 0, pid 444, write pid:444
----- executor 3 executes write_coverage_signal cov->size 0, flag collect 0
----- executor 3 signal number : 0
----- completed 17
execute_call 0, 0, 0, 0
execute_one loop: 0, 0, 0
#0 [82757ms] -> openat(0xffffffffffffffff, 0x20000380, 0x0, 0x11) 2462 /root/glusterfs-client/dfs-0-6
cover_reset in execute_call
#0 [82757ms] <- openat=0xffffffffffffffff errno=9 cover=0  /root/glusterfs-client/dfs-0-6
----- executor 3 write_call_output, size 0, pid 444, write pid:444
----- executor 3 executes write_coverage_signal cov->size 0, flag collect 0
----- executor 3 signal number : 0
----- completed 18
execute_call 0, 0, 0, 0
execute_one loop: 0, 0, 0
#0 [82757ms] -> setxattr$security_smack_transmute(0x20000080, 0x200000c0, 0x0, 0x0, 0x3) 3670 /root/glusterfs-client/dfs-0-6
cover_reset in execute_call
#0 [82757ms] <- setxattr$security_smack_transmute=0xffffffffffffffff errno=107 cover=0  /root/glusterfs-client/dfs-0-6
----- executor 3 write_call_output, size 0, pid 444, write pid:444
----- executor 3 executes write_coverage_signal cov->size 0, flag collect 0
----- executor 3 signal number : 0
----- completed 19
execute_call 0, 0, 0, 0
execute_one loop: 0, 0, 0
executor 3, execute_one inner time: 0, 6279, 0
execute_one time: 1, 6279
2023/03/05 05:02:39 for select break: 1
2023/03/05 05:02:39 --------- executor 3 receive reply, reply.done 1
executor 0 write_server_output
----- executor 0 executes write_coverage_signal cov->size 5418, flag collect 0
executor 2 write_server_output
----- executor 2 executes write_coverage_signal cov->size 617, flag collect 0
----- executor 2 signal number : 314
----- executor 2 executes write_coverage_signal cov->size 18, flag collect 0
----- executor 2 signal number : 4
----- executor 2 executes write_coverage_signal cov->size 4121, flag collect 0
----- executor 2 signal number : 1133
----- executor 2 executes write_coverage_signal cov->size 86, flag collect 0
----- executor 2 signal number : 14
----- executor 2 executes write_coverage_signal cov->size 163, flag collect 0
----- executor 2 signal number : 106
----- executor 2 executes write_coverage_signal cov->size 3, flag collect 0
----- executor 2 signal number : 2
----- executor 2 executes write_coverage_signal cov->size 132, flag collect 0
----- executor 2 signal number : 47
----- executor 2 executes write_coverage_signal cov->size 9050, flag collect 0
----- executor 2 signal number : 767
----- executor 2 executes write_coverage_signal cov->size 9878, flag collect 0
----- executor 2 signal number : 1566
----- executor 2 executes write_coverage_signal cov->size 34, flag collect 0
----- executor 2 signal number : 17
----- executor 2 executes write_coverage_signal cov->size 62, flag collect 0
----- executor 2 signal number : 16
----- executor 2 executes write_coverage_signal cov->size 8267, flag collect 0
----- executor 2 signal number : 844
----- executor 2 executes write_coverage_signal cov->size 10060, flag collect 0
----- executor 2 signal number : 999
----- executor 2 executes write_coverage_signal cov->size 9717, flag collect 0
----- executor 2 signal number : 545
----- executor 0 signal number : 549
----- executor 0 executes write_coverage_signal cov->size 32765, flag collect 0
----- executor 0 signal number : 88
----- executor 0 executes write_coverage_signal cov->size 17, flag collect 0
----- executor 0 signal number : 11
----- executor 0 executes write_coverage_signal cov->size 579, flag collect 0
----- executor 0 signal number : 93
----- executor 0 executes write_coverage_signal cov->size 5, flag collect 0
----- executor 0 signal number : 5
----- executor 0 executes write_coverage_signal cov->size 5, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 19, flag collect 0
----- executor 0 signal number : 5
----- executor 0 executes write_coverage_signal cov->size 209, flag collect 0
----- executor 0 signal number : 23
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 1
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 214, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 214, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 215, flag collect 0
----- executor 0 signal number : 0
----- executor 0 executes write_coverage_signal cov->size 8, flag collect 0
----- executor 0 signal number : 4
----- executor 0 executes write_coverage_signal cov->size 626, flag collect 0
----- executor 0 signal number : 66
----- executor 0 executes write_coverage_signal cov->size 1043, flag collect 0
----- executor 0 signal number : 102
----- executor 0 executes write_coverage_signal cov->size 1380, flag collect 0
executor 2 server cover_cnt 14 output_pos_value 6417
2023/03/05 05:02:39 for select break: 1
2023/03/05 05:02:39 --------- executor 2 receive reply, reply.done 1
time breakdown 2: 3374, 6293, 0
before receive testcase: 0 0
executor 3 write_metadata
time breakdown 3: 3128, 6281, 0
before receive testcase: 0 0
----- executor 0 signal number : 5
----- executor 0 executes write_coverage_signal cov->size 4737, flag collect 0
----- executor 0 signal number : 37
----- executor 0 executes write_coverage_signal cov->size 2956, flag collect 0
----- executor 0 signal number : 5
----- executor 0 executes write_coverage_signal cov->size 1663, flag collect 0
----- executor 0 signal number : 43
executor 0 server cover_cnt 43 output_pos_value 3490
executor 1 write_server_output
----- executor 1 executes write_coverage_signal cov->size 767, flag collect 0
----- executor 1 signal number : 335
time breakdown 0: 3397, 6298, 0
----- executor 1 executes write_coverage_signal cov->size 18, flag collect 0
----- executor 1 signal number : 4
before receive testcase: 0 1
2023/03/05 05:02:39 for select break: 1
2023/03/05 05:02:39 --------- executor 0 receive reply, reply.done 1
----- executor 1 executes write_coverage_signal cov->size 7632, flag collect 0
----- executor 1 signal number : 1820
----- executor 1 executes write_coverage_signal cov->size 86, flag collect 0
----- executor 1 signal number : 0
----- executor 1 executes write_coverage_signal cov->size 164, flag collect 0
----- executor 1 signal number : 107
----- executor 1 executes write_coverage_signal cov->size 3, flag collect 0
----- executor 1 signal number : 2
----- executor 1 executes write_coverage_signal cov->size 136, flag collect 0
----- executor 1 signal number : 47
----- executor 1 executes write_coverage_signal cov->size 10812, flag collect 0
----- executor 1 signal number : 757
----- executor 1 executes write_coverage_signal cov->size 9010, flag collect 0
----- executor 1 signal number : 28
----- executor 1 executes write_coverage_signal cov->size 32765, flag collect 0
----- executor 1 signal number : 2919
----- executor 1 executes write_coverage_signal cov->size 17, flag collect 0
----- executor 1 signal number : 16
----- executor 1 executes write_coverage_signal cov->size 63, flag collect 0
----- executor 1 signal number : 21
----- executor 1 executes write_coverage_signal cov->size 7396, flag collect 0
----- executor 1 signal number : 999
----- executor 1 executes write_coverage_signal cov->size 17115, flag collect 0
----- executor 1 signal number : 456
----- executor 1 executes write_coverage_signal cov->size 13608, flag collect 0
----- executor 1 signal number : 991
executor 1 server cover_cnt 15 output_pos_value 8548
2023/03/05 05:02:39 for select break: 1
time breakdown 1: 3380, 6321, 0
before receive testcase: 0 1
2023/03/05 05:02:39 --------- executor 1 receive reply, reply.done 1
2023/03/05 05:02:39 wg wait finish
2023/03/05 05:02:39 ------ all executors finish execution
2023/03/05 05:02:39 exec time: 9435
2023/03/05 05:02:39 ----- PS len: 4
2023/03/05 05:02:39 [CLIENT] executor 3 has 19 replies
2023/03/05 05:02:39 fuzzer receive 0 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 1584 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 305 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 497 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 17 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 0 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 7 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 433 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 0 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 208 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 1 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 0 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 0 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 0 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 0 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 0 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 0 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 0 signal and 0 cover from executor 3
2023/03/05 05:02:39 fuzzer receive 0 signal and 0 cover from executor 3
2023/03/05 05:02:39 ------ stat_cnt 0, [82 54 131 113 121 118 84 22 173 100]
2023/03/05 05:02:39 ----- parsed fsMd len 0
2023/03/05 05:02:39 [SERVER] executor 0 has 43 replies
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 456 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 1098 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 556 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 213 signal and 0 cover from userspace component
2023/03/05 05:02:39 [SERVER] executor 1 has 15 replies
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 549 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 88 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 11 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 335 signal and 0 cover from userspace component
2023/03/05 05:02:39 [SERVER] executor 2 has 14 replies
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 314 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 4 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 1133 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 14 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 106 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 2 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 47 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 767 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 1566 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 17 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 16 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 844 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 4 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 1820 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 107 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 2 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 999 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 2 receive 545 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 47 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 757 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 28 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 2919 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 16 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 21 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 999 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 456 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 1 receive 991 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 93 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 5 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 5 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 23 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 1 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 0 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 4 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 66 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 102 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 5 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 37 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 5 signal and 0 cover from userspace component
2023/03/05 05:02:39 ------- fuzzer executor 0 receive 43 signal and 0 cover from userspace component
2023/03/05 05:02:39 fsMds: [map[] map[] map[] map[]]
2023/03/05 05:02:39 result hanged=false: 
2023/03/05 05:02:39 ----- no new client coverage
2023/03/05 05:02:39 mutate testcase with failures
2023/03/05 05:02:39 ----- insertCall()
2023/03/05 05:02:39 ----- insertCall()
2023/03/05 05:02:39 ----- insertCall()
2023/03/05 05:02:39 ----- generateCall 121 chmod chmod
2023/03/05 05:02:39 ----- insertCall()
2023/03/05 05:02:39 ----- generateCall 2458 open open
2023/03/05 05:02:39 ----- insertCall()
2023/03/05 05:02:39 ----- mutateArg()
2023/03/05 05:02:39 #0: mutated
2023/03/05 05:02:39 HasCrashFail: true, .HasNetFail: false
2023/03/05 05:02:39 disable threaded and collide
2023/03/05 05:02:39 prog length: 6
2023/03/05 05:02:39 prog length: 6
2023/03/05 05:02:39 prog length: 8
2023/03/05 05:02:39 HasCrashFail:true HasNetFail:false
05:02:39 ---executing program 0:
syz_failure_recv(0x0)
syz_failure_down()
syz_failure_send(0x0)
syz_failure_recv(0x1)
syz_failure_up()
syz_failure_send(0x1)
---
syz_failure_recv(0x2)
syz_failure_down()
syz_failure_send(0x2)
syz_failure_recv(0x3)
syz_failure_up()
syz_failure_send(0x3)
---
---
syz_failure_sync(0x2, 0x3)
syz_failure_sync(0x3, 0x3)
open(&(0x7f0000000040)='./file0/file0\x00', 0x402240, 0x71)
mkdirat(0xffffffffffffff9c, &(0x7f00000003c0)='./file0\x00', 0x48)
chmod(&(0x7f0000000000)='./file0\x00', 0x2)
syz_failure_sync(0x0, 0x3)
syz_failure_sync(0x1, 0x3)
open(&(0x7f0000001700)='./file0/file0\x00', 0x40, 0x0)
---

end of program
----- executor 2 receive testcase
executor 2: prog_data_offset 1808, prog_size 8
[82808ms] exec opts: executor=2 procid=0 threaded=0 collide=0 cover=0 extra-cover=1 comps=0 dedup=1 timeouts=50/500000/1 prog=8 filter=0
----- executor 3 receive testcase
executor 3: prog_data_offset 1816, prog_size 832
[82811ms] exec opts: executor=3 procid=0 threaded=0 collide=0 cover=0 extra-cover=1 comps=0 dedup=1 timeouts=50/500000/1 prog=832 filter=0
remove dir: /root/glusterfs-client/dfs-0-6
opendir(/root/glusterfs-client/dfs-0-6) failedremove dir time 0
-----finish removing dir
----- executor 1 receive testcase
executor 1: prog_data_offset 1560, prog_size 248
[82770ms] exec opts: executor=1 procid=0 threaded=0 collide=0 cover=0 extra-cover=1 comps=0 dedup=1 timeouts=50/500000/1 prog=248 filter=0
----- executor 0 receive testcase
executor 0: prog_data_offset 1312, prog_size 248
[82816ms] exec opts: executor=0 procid=0 threaded=0 collide=0 cover=0 extra-cover=1 comps=0 dedup=1 timeouts=50/500000/1 prog=248 filter=0
Node-0:/root/daemon-log.842
2023/03/05 05:02:40 poll: candidates=0 inputs=0 signal=0
==842==WARNING: ASan doesn't fully support makecontext/swapcontext functions and may produce false positives in some cases!
